{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from six.moves import html_parser\n",
    "import unicodedata\n",
    "import HTMLParser\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  default = ''\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    #df.loc[i] = [d.get('title',default),d.get('categories',default)]\n",
    "    i += 1\n",
    "    #if i==100000: break\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "  \n",
    "\n",
    "df1 = getDF('meta_Clothing_Shoes_and_Jewelry.json.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create pickle\n",
    "#fileObject = open('./255_pickle/maindataframe.pickle','wb')\n",
    "#joblib.dump(df1, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read code\n",
    "#fileObject = open('./255_pickle/maindataframe.pickle','rb')\n",
    "#df1 = joblib.load(fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df1[['categories','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create pickle\n",
    "#fileObject = open('./255_pickle/df_final.pickle','wb')\n",
    "#joblib.dump(df_final, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read code\n",
    "#fileObject = open('./255_pickle/df_final.pickle','rb')\n",
    "#df_final = joblib.load(fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  give_full_path(category,posn):\n",
    "     try:\n",
    "        return ( ' -> '.join((category)[posn]))\n",
    "     except IndexError:\n",
    "        return 'no-category'\n",
    "     except TypeError:\n",
    "        return 'no-category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final['categories1'] =  df_final['categories'].apply(give_full_path,posn=0)\n",
    "df_final['categories2'] =  df_final['categories'].apply(give_full_path,posn=1)\n",
    "df_final['categories3'] =  df_final['categories'].apply(give_full_path,posn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lantin White Visor Wrap Around Ski Style Aviator Sunglasses with Black Lenses\n",
      "Clothing, Shoes & Jewelry -> Women -> Accessories -> Sunglasses & Eyewear Accessories -> Sunglasses\n",
      "Clothing, Shoes & Jewelry -> Men -> Accessories -> Sunglasses & Eyewear Accessories -> Sunglasses\n",
      "Clothing, Shoes & Jewelry -> Novelty, Costumes & More -> Band & Music Fan -> Accessories\n",
      "categories2                                          no-category\n",
      "categories1    Clothing, Shoes & Jewelry -> Girls -> Clothing...\n",
      "categories3                                          no-category\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##use this for demonstration\n",
    "print (df_final.loc[4][['title'][0]])\n",
    "print (df_final.loc[4][['categories1'][0]])\n",
    "print (df_final.loc[4][['categories2'][0]])\n",
    "print (df_final.loc[4][['categories3'][0]])\n",
    "print (df_final.loc[1][['categories2','categories1','categories3']])\n",
    "#print fullstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final.dropna(subset=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1st_category =df_final[(df_final['categories1'] != 'no-category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##retains deepest categories only for labels with single category \n",
    "category_path_df = df_1st_category.groupby('categories1').agg(np.size).reset_index()\n",
    "category_path_df.sort_values(by='categories1', inplace=True)\n",
    "category_path_df['category_path_next'] = category_path_df['categories1'].shift(-1)\n",
    "category_path_list = []\n",
    "for i, value in category_path_df.iterrows():\n",
    "    category_path = value['categories1']\n",
    "    category_path_next = value['category_path_next']\n",
    "    if str(category_path) not in str(category_path_next):\n",
    "        category_path_list.append(category_path)\n",
    "category_path_df = pd.DataFrame(category_path_list, columns=['category1'])\n",
    "df_1st_category = df_1st_category[df_1st_category['categories1'].isin(category_path_df['category1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2nd_category =df_1st_category[(df_1st_category['categories2'] != 'no-category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##retains deepest categories only for labels with two categories\n",
    "category_path_df = df_2nd_category.groupby('categories2').agg(np.size).reset_index()\n",
    "category_path_df.sort_values(by='categories2', inplace=True)\n",
    "category_path_df['category_path_next'] = category_path_df['categories2'].shift(-1)\n",
    "category_path_list = []\n",
    "for i, value in category_path_df.iterrows():\n",
    "    category_path = value['categories2']\n",
    "    category_path_next = value['category_path_next']\n",
    "    if str(category_path) not in str(category_path_next):\n",
    "        category_path_list.append(category_path)\n",
    "category_path_df = pd.DataFrame(category_path_list, columns=['category2'])\n",
    "df_2nd_category = df_2nd_category[df_2nd_category['categories2'].isin(category_path_df['category2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3rd_category =df_2nd_category[df_2nd_category['categories3'] != 'no-category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##retains deepest categories only for labels with three categories\n",
    "category_path_df = df_3rd_category.groupby('categories3').agg(np.size).reset_index()\n",
    "category_path_df.sort_values(by='categories3', inplace=True)\n",
    "category_path_df['category_path_next'] = category_path_df['categories3'].shift(-1)\n",
    "category_path_list = []\n",
    "for i, value in category_path_df.iterrows():\n",
    "    category_path = value['categories3']\n",
    "    category_path_next = value['category_path_next']\n",
    "    if str(category_path) not in str(category_path_next):\n",
    "        category_path_list.append(category_path)\n",
    "category_path_df = pd.DataFrame(category_path_list, columns=['category3'])\n",
    "df_3rd_category = df_3rd_category[df_3rd_category['categories3'].isin(category_path_df['category3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1st_category =df_1st_category[(df_1st_category['categories2'] == 'no-category') & (df_1st_category['categories3'] == 'no-category')].reset_index()\n",
    "df_2nd_category =df_2nd_category[df_2nd_category['categories3'] == 'no-category'].reset_index()\n",
    "df_3rd_category = df_3rd_category.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450014, 6)\n",
      "(213902, 6)\n",
      "(349445, 6)\n"
     ]
    }
   ],
   "source": [
    "print df_1st_category.shape\n",
    "print df_2nd_category.shape\n",
    "print df_3rd_category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index           int64\n",
      "categories     object\n",
      "title          object\n",
      "categories1    object\n",
      "categories2    object\n",
      "categories3    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_3rd_category.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2nd_category.index = df_2nd_category.index + 450014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3rd_category.index = df_3rd_category.index + 450014+213902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                                          1\n",
      "categories     [[Clothing, Shoes & Jewelry, Girls, Clothing, ...\n",
      "title                                 Ballet Dress-Up Fairy Tutu\n",
      "categories1    Clothing, Shoes & Jewelry -> Girls -> Clothing...\n",
      "categories2                                          no-category\n",
      "categories3                                          no-category\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_1st_category.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                                          3\n",
      "categories     [[Clothing, Shoes & Jewelry, Women, Accessorie...\n",
      "title          RiZ Women's Beautify Crafted &frac12; Rimmed F...\n",
      "categories1    Clothing, Shoes & Jewelry -> Women -> Accessor...\n",
      "categories2    Clothing, Shoes & Jewelry -> Novelty, Costumes...\n",
      "categories3                                          no-category\n",
      "Name: 450014, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_2nd_category.loc[450014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                                          4\n",
      "categories     [[Clothing, Shoes & Jewelry, Women, Accessorie...\n",
      "title          Lantin White Visor Wrap Around Ski Style Aviat...\n",
      "categories1    Clothing, Shoes & Jewelry -> Women -> Accessor...\n",
      "categories2    Clothing, Shoes & Jewelry -> Men -> Accessorie...\n",
      "categories3    Clothing, Shoes & Jewelry -> Novelty, Costumes...\n",
      "Name: 663916, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_3rd_category.loc[450014+213902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (df_3rd_category.loc[450014+213902]['categories3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_categories_data = pd.concat([df_1st_category,df_2nd_category,df_3rd_category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enc_title(cat_title):\n",
    "    try:\n",
    "        encoded_title = unicodedata.normalize('NFKD', unicode(cat_title, 'utf-8', 'ignore')).encode('ascii', 'ignore')\n",
    "        encoded_title = HTMLParser.HTMLParser().unescape(encoded_title).encode('ascii', 'ignore')\n",
    "        encoded_title = encoded_title.lower()\n",
    "        excluded='-/.%'\n",
    "        encoded_title=re.split(\"[^\" + excluded + \"\\w]+\",encoded_title)\n",
    "        word_set= [token for token in  encoded_title if not token.isdigit()]\n",
    "        stop = set(stopwords.words('english'))\n",
    "        word_set = [w for w in word_set if not w in stop]\n",
    "        word_set = [w for w in word_set if len(w) > 2]\n",
    "        encoded_title=(\" \".join(word_set))\n",
    "        \n",
    "    except TypeError:  \n",
    "        encoded_title = 'NA'\n",
    "\n",
    "    return encoded_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_categories_data['title'] =  combined_categories_data['title'].apply(enc_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_categories_data['combined_categories']= combined_categories_data[['categories1', 'categories2','categories3']].apply(lambda x: '<br>'.join(str(value) if str(value)!='no-category' else '<br>'  for value in x), axis=1)\n",
    "                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                   int64\n",
      "categories             object\n",
      "title                  object\n",
      "categories1            object\n",
      "categories2            object\n",
      "categories3            object\n",
      "combined_categories    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print combined_categories_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories1    Clothing, Shoes & Jewelry -> Shoes & Accessories: International Shipping Available\n",
      "categories2                                              Clothing, Shoes & Jewelry -> D -> Diesel\n",
      "categories3                         Clothing, Shoes & Jewelry -> Men -> Shoes -> Fashion Sneakers\n",
      "Name: 700000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print combined_categories_data.loc[700000][['categories1', 'categories2','categories3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clothing, Shoes & Jewelry -> Shoes & Accessories: International Shipping Available<br>Clothing, Shoes & Jewelry -> D -> Diesel<br>Clothing, Shoes & Jewelry -> Men -> Shoes -> Fashion Sneakers\n"
     ]
    }
   ],
   "source": [
    "print combined_categories_data.loc[700000]['combined_categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fileObject = open('./255_pickle/combined_categories_data.pickle','wb')\n",
    "#joblib.dump(combined_categories_data, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##read code\n",
    "fileObject = open('./255_pickle/combined_categories_data.pickle','rb')\n",
    "combined_categories_data = joblib.load(fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = combined_categories_data.sample(frac=.1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101336, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fileObject = open('./255_pickle/df.pickle','wb')\n",
    "#joblib.dump(df, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##read code\n",
    "from sklearn.externals import joblib\n",
    "fileObject = open('./255_pickle/df.pickle','rb')\n",
    "df = joblib.load(fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_small = df.sample(frac=0.3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fileObject = open('./255_pickle/df_small.pickle','wb')\n",
    "#joblib.dump(df_small, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##read code\n",
    "from sklearn.externals import joblib\n",
    "fileObject = open('./255_pickle/df_small.pickle','rb')\n",
    "df_small = joblib.load(fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "lin_clf = svm.LinearSVC()\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_small.title, df_small.combined_categories, test_size = 0.2, random_state = 42)\n",
    "vectorizer = TfidfVectorizer(norm = 'l2', use_idf = True,max_df=0.001, smooth_idf = False, sublinear_tf = True,ngram_range=(1,2))\n",
    "train_trans = vectorizer.fit_transform(train_x)\n",
    "train_trans = train_trans.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24320, 110632)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write vectorizer\n",
    "#fileObject = open('./255_pickle/vectorizer.pickle','wb')\n",
    "#joblib.dump(vectorizer, fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##read vectorizer\n",
    "#fileObject = open('./255_pickle/vectorizer.pickle','rb')\n",
    "#vectorizer = joblib.load(fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import SGDClassifier\n",
    "#clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "#clf.fit(train_trans, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_clf = RandomForestClassifier()\n",
    "random_clf.fit(train_trans,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf.fit(train_trans,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileObject = open('./255_pickle/lin_clf.pickle','wb')\n",
    "joblib.dump(lin_clf, fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fileObject = open('./255_pickle/lin_clf.pickle','rb')\n",
    "#lin_clf = joblib.load(fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_string = ['sports shoes']\n",
    "test_string = np.array(test_string)\n",
    "test_vector = vectorizer.transform(test_string).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 110632)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clothing, Shoes & Jewelry -> Women -> Shoes -> Sandals<br><br><br><br>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf.predict(test_vector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_for_acc = vectorizer.transform(test_x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = lin_clf.predict(test_for_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31507975661897714"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
